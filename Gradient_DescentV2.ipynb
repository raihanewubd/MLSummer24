{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raihanewubd/MLSummer24/blob/main/Gradient_DescentV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "aViIgRbqgkdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrd1K_SeEXMo"
      },
      "outputs": [],
      "source": [
        "!pip install ucimlrepo --quiet\n",
        "!pip install seaborn --quiet\n",
        "!pip install openpyxl==3.0.10 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "Kfz33X7wgw25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "pAWdEQ-bEavM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load California Housing Dataset"
      ],
      "metadata": {
        "id": "SjyDp4M6gztr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing = fetch_california_housing(as_frame=True)\n",
        "X = pd.DataFrame(data=housing.data, columns=housing.feature_names)\n",
        "y = pd.DataFrame(data=housing.target, columns=['MedHouseVal'])"
      ],
      "metadata": {
        "id": "VJRG-hjOEdEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA of the dataset**"
      ],
      "metadata": {
        "id": "ICdMiNhV9Z8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View first few rows\n",
        "print(X.head())\n",
        "\n",
        "# Get summary statistics\n",
        "print(X.describe())"
      ],
      "metadata": {
        "id": "-2zJhzs29eKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(X)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-fjze_G7-DsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = X.corr()\n",
        "# Check the available columns in the correlation matrix\n",
        "print(correlation_matrix.columns)\n",
        "\n",
        "# Assuming 'MedHouseVal' is in a separate DataFrame called 'y':\n",
        "correlations_with_target = X.corrwith(y['MedHouseVal'])\n",
        "print(correlations_with_target.sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "5Ok5QzGZ-MtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data into training and test**"
      ],
      "metadata": {
        "id": "i9M5fHkQ-Rk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X[['MedInc']], y, test_size=0.2, random_state=42)  # Replace with your selected features"
      ],
      "metadata": {
        "id": "rnGoHmToEiX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train shape: {X_train.shape} type: {type(X_train)}\")\n",
        "print(f\"y_train shape: {y_train.shape} type: {type(X_train)}\")\n",
        "print(f\"X_test shape: {X_test.shape} type: {type(X_train)}\")\n",
        "print(f\"y_test shape: {y_test.shape} type: {type(X_train)}\")"
      ],
      "metadata": {
        "id": "0Gjfl-6DE-ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Linear Regression with Gradient Descent"
      ],
      "metadata": {
        "id": "Gw8hKYuAg_c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLinearRegressionGD:\n",
        "    def __init__(self):\n",
        "        self.intercept = None\n",
        "        self.slope = None\n",
        "        self.intercept_history = []\n",
        "        self.slope_history = []\n",
        "        self.cost_history = []\n",
        "\n",
        "    def fit(self, X, y, learning_rate=0.001, num_iterations=1000):\n",
        "        print(\"Inside the fit method...\")\n",
        "        X = X.values.flatten()\n",
        "        y = y.values.flatten()\n",
        "\n",
        "        # Initialize parameters\n",
        "        self.intercept = 0\n",
        "        self.slope = 0\n",
        "\n",
        "        m = len(y)\n",
        "\n",
        "        for _ in range(num_iterations):\n",
        "            # Calculate partial derivatives\n",
        "            y_pred = self.predict(X)\n",
        "            dJ_dintercept = (1/m) * np.sum(y_pred - y)\n",
        "            dJ_dslope = (1/m) * np.sum((y_pred - y) * X)\n",
        "\n",
        "            # Update parameters\n",
        "            self.intercept -= learning_rate * dJ_dintercept\n",
        "            self.slope -= learning_rate * dJ_dslope\n",
        "            self.intercept_history.append(self.intercept)\n",
        "            self.slope_history.append(self.slope)\n",
        "            self.cost_history.append(np.mean((y_pred - y)**2))\n",
        "\n",
        "        print(\"Learned intercept:\", self.intercept)\n",
        "        print(\"Learned slope:\", self.slope)\n",
        "\n",
        "    def predict(self, X):\n",
        "        #X = X.values.flatten()\n",
        "        return self.intercept + self.slope * X"
      ],
      "metadata": {
        "id": "3MNFXgU-EtAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and predicting**"
      ],
      "metadata": {
        "id": "gKyjCuYThLc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_train.dtypes, y_train.dtypes)\n",
        "print(X_test.shape, y_test.shape, X_test.dtypes, y_test.dtypes)\n",
        "# Assuming X_train and y_train are already defined\n",
        "model = SimpleLinearRegressionGD()\n",
        "#try:\n",
        "print(\"Starting the fit method...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Fit method complete.\")\n",
        "#except Exception as e:\n",
        "#    print(f\"An error occurred during fitting: {e}\")\n",
        "print(f\"self.intercept = {model.intercept}\")\n",
        "print(f\"self.slope = {model.slope}\")\n",
        "# Make predictions on new data\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('y_pred:', y_pred.shape)\n",
        "print('MSE:', mse)\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r2)"
      ],
      "metadata": {
        "id": "r9m0d1R2EyiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot the learning curve**"
      ],
      "metadata": {
        "id": "E9jBDoGx_txo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have trained your model as 'model'\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(y=model.intercept_history, mode='lines', name='Intercept'))\n",
        "fig.add_trace(go.Scatter(y=model.slope_history, mode='lines', name='Slope'))\n",
        "fig.add_trace(go.Scatter(y=model.cost_history, mode='lines', name='Cost'))\n",
        "\n",
        "fig.update_layout(title='Training History',\n",
        "                  xaxis_title='Iteration',\n",
        "                  yaxis_title='Value')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "aRYy7pXA_qyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot the search space of simple linear regression**"
      ],
      "metadata": {
        "id": "LGogRILm-95d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intercept_history = []\n",
        "slope_history = []\n",
        "cost_history = []\n",
        "\n",
        "# Generate a range of values for slope and intercept\n",
        "slope_range = np.linspace(-10, 10, 100)\n",
        "intercept_range = np.linspace(-10, 10, 100)\n",
        "\n",
        "# Create a meshgrid from the ranges\n",
        "slope_grid, intercept_grid = np.meshgrid(slope_range, intercept_range)\n",
        "\n",
        "# Calculate the cost function (MSE) for each combination of slope and intercept\n",
        "# Assuming X_train and y_train are defined from your previous code\n",
        "cost_grid = np.zeros_like(slope_grid)\n",
        "for i in range(slope_grid.shape[0]):\n",
        "    for j in range(slope_grid.shape[1]):\n",
        "        y_pred = slope_grid[i, j] * X_train.values + intercept_grid[i, j]\n",
        "        cost_grid[i, j] = np.mean((y_pred - y_train.values)**2)\n",
        "\n"
      ],
      "metadata": {
        "id": "fBB71X1c_ROv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Create a Plotly figure\n",
        "fig = go.Figure(data=[go.Surface(z=cost_grid, x=slope_grid, y=intercept_grid)])\n",
        "\n",
        "# Update the layout\n",
        "fig.update_layout(title='Search Space for Single Linear Regression',\n",
        "                  scene=dict(xaxis_title='Slope',\n",
        "                             yaxis_title='Intercept',\n",
        "                             zaxis_title='Cost (MSE)'))\n",
        "\n",
        "# Display the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "lXfpVgtU_XiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Actual vs predicted plot**"
      ],
      "metadata": {
        "id": "4JQP5oAhAYjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Assuming X_test, y_test, and y_pred are pandas DataFrames\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a scatter plot for the actual values\n",
        "fig.add_trace(go.Scatter(x=X_test.values.flatten(), y=y_test.values.flatten(), mode='markers', name='Actual', marker=dict(symbol='circle')))\n",
        "\n",
        "# Add a scatter plot for the predicted values\n",
        "fig.add_trace(go.Scatter(x=X_test.values.flatten(), y=y_pred.values.flatten(), mode='markers', name='Predicted', marker=dict(symbol='diamond')))\n",
        "\n",
        "# Update the layout\n",
        "fig.update_layout(title='Actual vs Predicted Values',\n",
        "                  xaxis_title='MedInc',\n",
        "                  yaxis_title='MedHouseVal')\n",
        "\n",
        "# Display the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "72MBUYw_-3iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Intercept, Slope and Cost**"
      ],
      "metadata": {
        "id": "ouMf0-wvhTgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=model.intercept_history,\n",
        "    y=model.slope_history,\n",
        "    z=model.cost_history,\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color=model.cost_history,                # set color to an array/list of desired values\n",
        "        colorscale='Viridis',   # choose a colorscale\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig.update_layout(\n",
        "    title='3D Scatter Plot',\n",
        "    scene=dict(\n",
        "        xaxis_title='Intercept History',\n",
        "        yaxis_title='Slope History',\n",
        "        zaxis_title='Cost History'\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "VpMzUa0bH5bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Intercept, Slope and Cost with respect to search space**"
      ],
      "metadata": {
        "id": "AwNkJmMChhXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the range for intercept and slope\n",
        "intercept_range = np.linspace(min(model.intercept_history), max(model.intercept_history), 50)\n",
        "slope_range = np.linspace(min(model.slope_history), max(model.slope_history), 50)\n",
        "\n",
        "# Create a mesh grid\n",
        "intercept_grid, slope_grid = np.meshgrid(intercept_range, slope_range)\n",
        "\n",
        "# Calculate the cost for each point in the grid (assuming a simple linear regression cost function)\n",
        "cost_grid = np.zeros(intercept_grid.shape)\n",
        "for i in range(intercept_grid.shape[0]):\n",
        "    for j in range(intercept_grid.shape[1]):\n",
        "        intercept = intercept_grid[i, j]\n",
        "        slope = slope_grid[i, j]\n",
        "        # Assuming model.X and model.y are your data points\n",
        "        predictions = intercept + slope * X_train.values\n",
        "        cost_grid[i, j] = np.mean((predictions - y_train.values) ** 2)\n",
        "\n",
        "# Add the search space to the plot\n",
        "fig.add_trace(go.Surface(\n",
        "    x=intercept_grid,\n",
        "    y=slope_grid,\n",
        "    z=cost_grid,\n",
        "    colorscale='Viridis',\n",
        "    opacity=0.5,\n",
        "    showscale=False\n",
        "))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2HSadDaaIV1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Linear Regression with Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "uRsVrHbmqevS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLinearRegressionSGD:\n",
        "    def __init__(self):\n",
        "        self.intercept = None\n",
        "        self.slope = None\n",
        "        self.intercept_history = []\n",
        "        self.slope_history = []\n",
        "        self.cost_history = []\n",
        "\n",
        "    def fit(self, X, y, learning_rate=0.001, num_iterations=1000):\n",
        "        print(\"Inside the fit method...\")\n",
        "        X = X.values.flatten()\n",
        "        y = y.values.flatten()\n",
        "\n",
        "        # Initialize parameters\n",
        "        self.intercept = 0\n",
        "        self.slope = 0\n",
        "\n",
        "        m = len(y)\n",
        "\n",
        "        for _ in range(num_iterations):\n",
        "            # Shuffle data for stochasticity\n",
        "            random_index = np.random.randint(0, m)\n",
        "            xi = X[random_index]\n",
        "            yi = y[random_index]\n",
        "\n",
        "            # Calculate prediction for the single data point\n",
        "            y_pred_i = self.predict(xi)\n",
        "\n",
        "            # Calculate partial derivatives for the single data point\n",
        "            dJ_dintercept = 2 * (y_pred_i - yi)\n",
        "            dJ_dslope = 2 * (y_pred_i - yi) * xi\n",
        "\n",
        "            # Update parameters\n",
        "            self.intercept -= learning_rate * dJ_dintercept\n",
        "            self.slope -= learning_rate * dJ_dslope\n",
        "\n",
        "            # Store history (optional)\n",
        "            self.intercept_history.append(self.intercept)\n",
        "            self.slope_history.append(self.slope)\n",
        "\n",
        "            # Calculate cost for the entire dataset (optional)\n",
        "            y_pred_all = self.predict(X)\n",
        "            cost = np.mean((y_pred_all - y)**2)\n",
        "            self.cost_history.append(cost)\n",
        "\n",
        "        print(\"Learned intercept:\", self.intercept)\n",
        "        print(\"Learned slope:\", self.slope)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if isinstance(X, np.ndarray):  # Handle both single value and array inputs\n",
        "            return self.intercept + self.slope * X\n",
        "        else:\n",
        "            return self.intercept + self.slope * np.array(X)  # Convert to array if needed"
      ],
      "metadata": {
        "id": "uFdlRZIcU87A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and predicting**"
      ],
      "metadata": {
        "id": "9FfkMziWqwYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_train.dtypes, y_train.dtypes)\n",
        "print(X_test.shape, y_test.shape, X_test.dtypes, y_test.dtypes)\n",
        "# Assuming X_train and y_train are already defined\n",
        "model = SimpleLinearRegressionSGD()\n",
        "#try:\n",
        "print(\"Starting the fit method...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Fit method complete.\")\n",
        "#except Exception as e:\n",
        "#    print(f\"An error occurred during fitting: {e}\")\n",
        "print(f\"self.intercept = {model.intercept}\")\n",
        "print(f\"self.slope = {model.slope}\")\n",
        "# Make predictions on new data\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('y_pred:', y_pred.shape)\n",
        "print('MSE:', mse)\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r2)"
      ],
      "metadata": {
        "id": "KMnfRnoodALa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Intercept, Slope and Cost**"
      ],
      "metadata": {
        "id": "vBjkzZluq0ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=model.intercept_history,\n",
        "    y=model.slope_history,\n",
        "    z=model.cost_history,\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color=model.cost_history,                # set color to an array/list of desired values\n",
        "        colorscale='Viridis',   # choose a colorscale\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig.update_layout(\n",
        "    title='3D Scatter Plot',\n",
        "    scene=dict(\n",
        "        xaxis_title='Intercept History',\n",
        "        yaxis_title='Slope History',\n",
        "        zaxis_title='Cost History'\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "lUPZtnMDdRP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Intercept, Slope and Cost with respect to search space**"
      ],
      "metadata": {
        "id": "0n8_k3SFq3Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the range for intercept and slope\n",
        "intercept_range = np.linspace(min(model.intercept_history), max(model.intercept_history), 50)\n",
        "slope_range = np.linspace(min(model.slope_history), max(model.slope_history), 50)\n",
        "\n",
        "# Create a mesh grid\n",
        "intercept_grid, slope_grid = np.meshgrid(intercept_range, slope_range)\n",
        "\n",
        "# Calculate the cost for each point in the grid (assuming a simple linear regression cost function)\n",
        "cost_grid = np.zeros(intercept_grid.shape)\n",
        "for i in range(intercept_grid.shape[0]):\n",
        "    for j in range(intercept_grid.shape[1]):\n",
        "        intercept = intercept_grid[i, j]\n",
        "        slope = slope_grid[i, j]\n",
        "        # Assuming model.X and model.y are your data points\n",
        "        predictions = intercept + slope * X_train.values\n",
        "        cost_grid[i, j] = np.mean((predictions - y_train.values) ** 2)\n",
        "\n",
        "# Add the search space to the plot\n",
        "fig.add_trace(go.Surface(\n",
        "    x=intercept_grid,\n",
        "    y=slope_grid,\n",
        "    z=cost_grid,\n",
        "    colorscale='Viridis',\n",
        "    opacity=0.5,\n",
        "    showscale=False\n",
        "))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "m-oKxAz9dnGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Linear Regression with Adam"
      ],
      "metadata": {
        "id": "ZOa3INpLq8DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class SimpleLinearRegressionAdam:\n",
        "    def __init__(self):\n",
        "        self.intercept = None\n",
        "        self.slope = None\n",
        "        self.intercept_history = []\n",
        "        self.slope_history = []\n",
        "        self.cost_history = []\n",
        "\n",
        "    def fit(self, X, y, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, num_iterations=1000):\n",
        "        print(\"Inside the fit method...\")\n",
        "        X = X.values.flatten()\n",
        "        y = y.values.flatten()\n",
        "\n",
        "        # Initialize parameters\n",
        "        self.intercept = 0\n",
        "        self.slope = 0\n",
        "\n",
        "        m = len(y)\n",
        "\n",
        "        # Initialize Adam parameters\n",
        "        v_intercept = 0\n",
        "        v_slope = 0\n",
        "        s_intercept = 0\n",
        "        s_slope = 0\n",
        "        t = 0\n",
        "\n",
        "        for _ in range(num_iterations):\n",
        "            t += 1  # Iteration counter\n",
        "\n",
        "            # Shuffle data (for stochasticity)\n",
        "            random_index = np.random.randint(0, m)\n",
        "            xi = X[random_index]\n",
        "            yi = y[random_index]\n",
        "\n",
        "            # Calculate prediction for the single data point\n",
        "            y_pred_i = self.predict(xi)\n",
        "\n",
        "            # Calculate partial derivatives for the single data point\n",
        "            dJ_dintercept = 2 * (y_pred_i - yi)\n",
        "            dJ_dslope = 2 * (y_pred_i - yi) * xi\n",
        "\n",
        "            # Update biased first moment estimates\n",
        "            v_intercept = beta1 * v_intercept + (1 - beta1) * dJ_dintercept\n",
        "            v_slope = beta1 * v_slope + (1 - beta1) * dJ_dslope\n",
        "\n",
        "            # Update biased second raw moment estimates\n",
        "            s_intercept = beta2 * s_intercept + (1 - beta2) * dJ_dintercept**2\n",
        "            s_slope = beta2 * s_slope + (1 - beta2) * dJ_dslope**2\n",
        "\n",
        "            # Compute bias-corrected first moment estimates\n",
        "            v_intercept_corrected = v_intercept / (1 - beta1**t)\n",
        "            v_slope_corrected = v_slope / (1 - beta1**t)\n",
        "\n",
        "            # Compute bias-corrected second raw moment estimates\n",
        "            s_intercept_corrected = s_intercept / (1 - beta2**t)\n",
        "            s_slope_corrected = s_slope / (1 - beta2**t)\n",
        "\n",
        "            # Update parameters using Adam\n",
        "            self.intercept -= learning_rate * v_intercept_corrected / (np.sqrt(s_intercept_corrected) + epsilon)\n",
        "            self.slope -= learning_rate * v_slope_corrected / (np.sqrt(s_slope_corrected) + epsilon)\n",
        "\n",
        "            # Store history (optional)\n",
        "            self.intercept_history.append(self.intercept)\n",
        "            self.slope_history.append(self.slope)\n",
        "\n",
        "            # Calculate cost for the entire dataset (optional)\n",
        "            y_pred_all = self.predict(X)\n",
        "            cost = np.mean((y_pred_all - y)**2)\n",
        "            self.cost_history.append(cost)\n",
        "\n",
        "        print(\"Learned intercept:\", self.intercept)\n",
        "        print(\"Learned slope:\", self.slope)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if isinstance(X, np.ndarray):  # Handle both single value and array inputs\n",
        "            return self.intercept + self.slope * X\n",
        "        else:\n",
        "            return self.intercept + self.slope * np.array(X)  # Convert to array if needed"
      ],
      "metadata": {
        "id": "-ZfCSP3Je6ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and predicting**"
      ],
      "metadata": {
        "id": "mx9SnfzwrLBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_train.dtypes, y_train.dtypes)\n",
        "print(X_test.shape, y_test.shape, X_test.dtypes, y_test.dtypes)\n",
        "# Assuming X_train and y_train are already defined\n",
        "model = SimpleLinearRegressionAdam()\n",
        "#try:\n",
        "print(\"Starting the fit method...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Fit method complete.\")\n",
        "#except Exception as e:\n",
        "#    print(f\"An error occurred during fitting: {e}\")\n",
        "print(f\"self.intercept = {model.intercept}\")\n",
        "print(f\"self.slope = {model.slope}\")\n",
        "# Make predictions on new data\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('y_pred:', y_pred.shape)\n",
        "print('MSE:', mse)\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r2)"
      ],
      "metadata": {
        "id": "wvFuJ0Sfe_Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Intercept, Slope and Cost**"
      ],
      "metadata": {
        "id": "1IT8GNDJrnIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=model.intercept_history,\n",
        "    y=model.slope_history,\n",
        "    z=model.cost_history,\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color=model.cost_history,                # set color to an array/list of desired values\n",
        "        colorscale='Viridis',   # choose a colorscale\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig.update_layout(\n",
        "    title='3D Scatter Plot',\n",
        "    scene=dict(\n",
        "        xaxis_title='Intercept History',\n",
        "        yaxis_title='Slope History',\n",
        "        zaxis_title='Cost History'\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "cgCfEqwJfHhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Intercept, Slope and Cost with respect to search space**"
      ],
      "metadata": {
        "id": "Eqkpz3E_rRwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the range for intercept and slope\n",
        "intercept_range = np.linspace(min(model.intercept_history), max(model.intercept_history), 50)\n",
        "slope_range = np.linspace(min(model.slope_history), max(model.slope_history), 50)\n",
        "\n",
        "# Create a mesh grid\n",
        "intercept_grid, slope_grid = np.meshgrid(intercept_range, slope_range)\n",
        "\n",
        "# Calculate the cost for each point in the grid (assuming a simple linear regression cost function)\n",
        "cost_grid = np.zeros(intercept_grid.shape)\n",
        "for i in range(intercept_grid.shape[0]):\n",
        "    for j in range(intercept_grid.shape[1]):\n",
        "        intercept = intercept_grid[i, j]\n",
        "        slope = slope_grid[i, j]\n",
        "        # Assuming model.X and model.y are your data points\n",
        "        predictions = intercept + slope * X_train.values\n",
        "        cost_grid[i, j] = np.mean((predictions - y_train.values) ** 2)\n",
        "\n",
        "# Add the search space to the plot\n",
        "fig.add_trace(go.Surface(\n",
        "    x=intercept_grid,\n",
        "    y=slope_grid,\n",
        "    z=cost_grid,\n",
        "    colorscale='Viridis',\n",
        "    opacity=0.5,\n",
        "    showscale=False\n",
        "))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "3CI4EYqwfTWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic ANN"
      ],
      "metadata": {
        "id": "pHicfJDJzAa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class SimpleANN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.weight_history = []\n",
        "        self.cost_history = []\n",
        "\n",
        "        # Initialize weights with random values\n",
        "        self.weights1 = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.bias1 = np.zeros((1, self.hidden_size))\n",
        "        self.weights2 = np.random.randn(self.hidden_size, self.output_size)\n",
        "        self.bias2 = np.zeros((1, self.output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Forward propagation\n",
        "        self.hidden_layer_input = np.dot(X, self.weights1) + self.bias1\n",
        "        self.hidden_layer_output = self.sigmoid(self.hidden_layer_input)\n",
        "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights2) + self.bias2\n",
        "        self.predicted_output = self.sigmoid(self.output_layer_input)\n",
        "        return self.predicted_output\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        # Sigmoid activation function\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def sigmoid_derivative(self, z):\n",
        "        # Derivative of sigmoid function\n",
        "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        # Backpropagation\n",
        "        error = y - self.predicted_output\n",
        "        d_predicted_output = error * self.sigmoid_derivative(self.output_layer_input)\n",
        "\n",
        "        error_hidden_layer = d_predicted_output.dot(self.weights2.T)\n",
        "        d_hidden_layer = error_hidden_layer * self.sigmoid_derivative(self.hidden_layer_input)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights2 += self.hidden_layer_output.T.dot(d_predicted_output) * learning_rate\n",
        "        self.bias2 += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
        "        self.weights1 += X.T.dot(d_hidden_layer) * learning_rate\n",
        "        self.bias1 += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
        "        self.weight_history.append([self.weights1.copy(), self.weights2.copy()])\n",
        "\n",
        "    def train(self, X, y, learning_rate, num_iterations):\n",
        "        # Training loop\n",
        "        for _ in range(num_iterations):\n",
        "            self.forward(X)\n",
        "            self.backward(X, y, learning_rate)\n",
        "            predictions = self.forward(X)\n",
        "            cost = np.mean((predictions - y) ** 2)\n",
        "            self.cost_history.append(cost)\n",
        "\n",
        "# Example usage:\n",
        "# Create a SimpleANN with 2 inputs, 5 hidden neurons, and 1 output\n",
        "model = SimpleANN(input_size=2, hidden_size=5, output_size=1)\n",
        "\n",
        "# Some sample input data and labels\n",
        "X = np.array([[0.5, 0.3], [0.2, 0.7]])\n",
        "y = np.array([[0.8], [0.3]])\n",
        "\n",
        "# Train the model\n",
        "model.train(X, y, learning_rate=0.1, num_iterations=1000)\n",
        "\n",
        "# Get predictions after training\n",
        "predictions = model.forward(X)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "fblmw_OYzzJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select two weights to visualize (adjust indices as needed)\n",
        "weight1_idx = (0, 0)  # First weight in the first layer\n",
        "weight2_idx = (0, 0)  # First weight in the second layer\n",
        "\n",
        "# Create a grid of weight values\n",
        "weight1_values = np.linspace(-10, 10, 30)\n",
        "weight2_values = np.linspace(-10, 10, 30)\n",
        "weight1_grid, weight2_grid = np.meshgrid(weight1_values, weight2_values)\n",
        "\n",
        "# Evaluate cost for each weight combination\n",
        "cost_grid = np.zeros_like(weight1_grid)\n",
        "for i in range(weight1_grid.shape[0]):\n",
        "    for j in range(weight1_grid.shape[1]):\n",
        "        # Temporarily modify the selected weights\n",
        "        model.weights1[weight1_idx] = weight1_grid[i, j]\n",
        "        model.weights2[weight2_idx] = weight2_grid[i, j]\n",
        "\n",
        "        # Calculate cost\n",
        "        predictions = model.forward(X)\n",
        "        cost = np.mean((predictions - y) ** 2)\n",
        "        cost_grid[i, j] = cost\n",
        "\n",
        "        # Reset weights to their original values (important!)\n",
        "        model.weights1[weight1_idx] = model.weight_history[-1][0][weight1_idx]\n",
        "        model.weights2[weight2_idx] = model.weight_history[-1][1][weight2_idx]\n",
        "\n",
        "# Create the 3D surface plot\n",
        "fig = go.Figure(data=[go.Surface(z=cost_grid, x=weight1_grid, y=weight2_grid)])\n",
        "fig.update_layout(title='Search Space Visualization', scene=dict(xaxis_title='Weight 1', yaxis_title='Weight 2', zaxis_title='Cost'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "N5IxLe_S1faD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Task\n",
        "\n",
        "\n",
        "1.   Predict the california house prise using basic ANN. The basic ANN will have three layers. 1) Input layer with one input, 2) Hidden layer with N number of neurons and use sigmod activation function, 3)Output layer with one output. Use the three different Gradient Descent algorithms (Gradient Descent,  Stochatic Gradient Descent, and  Adam Optimizer) as back propagation\n",
        "2.   Plot the Actual vs Predicted House Price\n",
        "3.   Plot the learning curve\n",
        "4.   Plot weight, cost during in each iteration into the search space for\n",
        "      *   Gradient Descent\n",
        "      *   Stochatic Gradient Descent\n",
        "      *   Adam Optimizer\n",
        "\n",
        "**Submision**\n",
        "\n",
        "1.   Present the code to instructor.\n",
        "2.   Prepare report where you analysize the three different gradient descent algorithms and its performance.\n",
        "3. Submit the code and report in classroom in a zip file\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1q7lcyXDAmS3"
      }
    }
  ]
}